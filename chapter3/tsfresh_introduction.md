# tsfresh è¯¦ç»†ä»‹ç»ä¸ä½¿ç”¨æŒ‡å—

## ç›®å½•
- [1. tsfresh ç®€ä»‹](#1-tsfresh-ç®€ä»‹)
- [2. æ ¸å¿ƒæ¦‚å¿µ](#2-æ ¸å¿ƒæ¦‚å¿µ)
- [3. å®‰è£…ä¸é…ç½®](#3-å®‰è£…ä¸é…ç½®)
- [4. åŸºæœ¬ç”¨æ³•](#4-åŸºæœ¬ç”¨æ³•)
- [5. é«˜çº§åŠŸèƒ½](#5-é«˜çº§åŠŸèƒ½)
- [6. å®é™…åº”ç”¨æ¡ˆä¾‹](#6-å®é™…åº”ç”¨æ¡ˆä¾‹)
- [7. æœ€ä½³å®è·µ](#7-æœ€ä½³å®è·µ)
- [8. å¸¸è§é—®é¢˜](#8-å¸¸è§é—®é¢˜)

---

## 1. tsfresh ç®€ä»‹

### 1.1 ä»€ä¹ˆæ˜¯ tsfreshï¼Ÿ

**tsfresh**ï¼ˆTime Series Feature extraction based on scalable hypothesis testsï¼‰æ˜¯ä¸€ä¸ªç”¨äº**æ—¶é—´åºåˆ—ç‰¹å¾æå–**çš„ Python åº“ã€‚

### 1.2 ä¸»è¦ç‰¹ç‚¹

- ğŸš€ **è‡ªåŠ¨åŒ–ç‰¹å¾å·¥ç¨‹**ï¼šè‡ªåŠ¨ä»æ—¶é—´åºåˆ—ä¸­æå–å¤§é‡ç»Ÿè®¡ç‰¹å¾
- ğŸ“Š **ç‰¹å¾é€‰æ‹©**ï¼šåŸºäºå‡è®¾æ£€éªŒè‡ªåŠ¨ç­›é€‰ç›¸å…³ç‰¹å¾
- âš¡ **é«˜æ€§èƒ½**ï¼šæ”¯æŒå¹¶è¡Œè®¡ç®—ï¼Œå¤„ç†å¤§è§„æ¨¡æ•°æ®é›†
- ğŸ¯ **é€‚ç”¨åœºæ™¯å¹¿æ³›**ï¼šé‡‘èã€åŒ»ç–—ã€å·¥ä¸šã€é£æ§ç­‰é¢†åŸŸ

### 1.3 æ ¸å¿ƒä¼˜åŠ¿

| ä¼˜åŠ¿ | è¯´æ˜ |
|------|------|
| **è‡ªåŠ¨åŒ–** | æ— éœ€æ‰‹åŠ¨è®¾è®¡ç‰¹å¾ï¼Œè‡ªåŠ¨æå–800+ç§ç‰¹å¾ |
| **ç§‘å­¦æ€§** | åŸºäºç»Ÿè®¡å‡è®¾æ£€éªŒç­›é€‰ç‰¹å¾ï¼Œé¿å…è¿‡æ‹Ÿåˆ |
| **å¯æ‰©å±•** | æ”¯æŒåˆ†å¸ƒå¼è®¡ç®—ï¼Œå¤„ç†TBçº§æ•°æ® |
| **æ˜“ç”¨æ€§** | APIç®€æ´ï¼Œä¸pandasã€sklearnæ— ç¼é›†æˆ |

---

## 2. æ ¸å¿ƒæ¦‚å¿µ

### 2.1 æ—¶é—´åºåˆ—æ•°æ®æ ¼å¼

tsfresh è¦æ±‚æ•°æ®åŒ…å«ä»¥ä¸‹ä¸‰ä¸ªå…³é”®åˆ—ï¼š

```python
| id  | time | value |
|-----|------|-------|
| 1   | 0    | 3.5   |
| 1   | 1    | 4.2   |
| 1   | 2    | 3.8   |
| 2   | 0    | 5.1   |
| 2   | 1    | 4.9   |
```

- **id**ï¼šæ ‡è¯†ä¸åŒçš„æ—¶é—´åºåˆ—ï¼ˆå¦‚ç”¨æˆ·IDã€è®¢å•IDï¼‰
- **time**ï¼šæ—¶é—´æˆ³æˆ–åºåˆ—ç´¢å¼•
- **value**ï¼šè§‚æµ‹å€¼

### 2.2 ç‰¹å¾ç±»åˆ«

tsfresh æå–çš„ç‰¹å¾åˆ†ä¸ºä»¥ä¸‹å‡ ç±»ï¼š

#### 2.2.1 ç»Ÿè®¡ç‰¹å¾
- å‡å€¼ã€ä¸­ä½æ•°ã€æ–¹å·®ã€æ ‡å‡†å·®
- æœ€å¤§å€¼ã€æœ€å°å€¼ã€æå·®
- ååº¦ï¼ˆskewnessï¼‰ã€å³°åº¦ï¼ˆkurtosisï¼‰
- åˆ†ä½æ•°ï¼ˆ25%, 50%, 75%ï¼‰

#### 2.2.2 æ—¶åºç‰¹å¾
- è‡ªç›¸å…³ç³»æ•°ï¼ˆAutocorrelationï¼‰
- åè‡ªç›¸å…³ç³»æ•°ï¼ˆPartial Autocorrelationï¼‰
- è¶‹åŠ¿å¼ºåº¦
- å­£èŠ‚æ€§æŒ‡æ ‡

#### 2.2.3 é¢‘åŸŸç‰¹å¾
- å‚…é‡Œå¶å˜æ¢ç³»æ•°
- åŠŸç‡è°±å¯†åº¦
- é¢‘è°±è´¨å¿ƒ

#### 2.2.4 å¤æ‚åº¦ç‰¹å¾
- è¿‘ä¼¼ç†µï¼ˆApproximate Entropyï¼‰
- æ ·æœ¬ç†µï¼ˆSample Entropyï¼‰
- C3ç»Ÿè®¡é‡
- CIDï¼ˆComplexity-Invariant Distanceï¼‰

#### 2.2.5 å½¢æ€ç‰¹å¾
- å³°å€¼æ•°é‡
- è¿‡é›¶ç‚¹æ•°é‡
- é•¿åº¦ç»Ÿè®¡
- å˜åŒ–ç‡

---

## 3. å®‰è£…ä¸é…ç½®

### 3.1 å®‰è£…

```bash
# åŸºç¡€å®‰è£…
pip install tsfresh

# åŒ…å«æ‰€æœ‰ä¾èµ–
pip install tsfresh[all]

# ç‰¹å®šç‰ˆæœ¬
pip install tsfresh==0.20.1
```

### 3.2 ä¾èµ–åº“

```python
# æ ¸å¿ƒä¾èµ–
numpy >= 1.15.1
pandas >= 0.25.0
scipy >= 1.2.0
statsmodels >= 0.9.0
scikit-learn >= 0.22.0

# å¯é€‰ä¾èµ–
dask  # åˆ†å¸ƒå¼è®¡ç®—
```

### 3.3 éªŒè¯å®‰è£…

```python
import tsfresh
print(tsfresh.__version__)
```

---

## 4. åŸºæœ¬ç”¨æ³•

### 4.1 å¿«é€Ÿå¼€å§‹

#### ç¤ºä¾‹1ï¼šæœ€ç®€å•çš„ç”¨æ³•

```python
from tsfresh import extract_features
import pandas as pd

# å‡†å¤‡æ—¶é—´åºåˆ—æ•°æ®
df = pd.DataFrame({
    'id': [1, 1, 1, 2, 2, 2],
    'time': [0, 1, 2, 0, 1, 2],
    'value': [3.5, 4.2, 3.8, 5.1, 4.9, 5.3]
})

# æå–ç‰¹å¾
features = extract_features(df, column_id='id', column_sort='time')
print(features.shape)  # è¾“å‡ºï¼š(2, 794) - 2ä¸ªIDï¼Œ794ä¸ªç‰¹å¾
```

#### ç¤ºä¾‹2ï¼šå¤šå˜é‡æ—¶é—´åºåˆ—

```python
df = pd.DataFrame({
    'id': [1, 1, 1, 2, 2, 2],
    'time': [0, 1, 2, 0, 1, 2],
    'value1': [3.5, 4.2, 3.8, 5.1, 4.9, 5.3],
    'value2': [1.2, 1.5, 1.1, 2.0, 1.8, 2.1]
})

# è‡ªåŠ¨è¯†åˆ«æ‰€æœ‰æ•°å€¼åˆ—ä½œä¸ºç‰¹å¾åˆ—
features = extract_features(
    df, 
    column_id='id', 
    column_sort='time'
)
```

### 4.2 ç‰¹å¾æå–é…ç½®

#### 4.2.1 ä½¿ç”¨é¢„å®šä¹‰è®¾ç½®

```python
from tsfresh.feature_extraction import ComprehensiveFCParameters, MinimalFCParameters

# æœ€å°ç‰¹å¾é›†ï¼ˆå¿«é€Ÿï¼‰
minimal_features = extract_features(
    df, 
    column_id='id', 
    column_sort='time',
    default_fc_parameters=MinimalFCParameters()
)

# å®Œæ•´ç‰¹å¾é›†ï¼ˆå…¨é¢ï¼‰
comprehensive_features = extract_features(
    df, 
    column_id='id', 
    column_sort='time',
    default_fc_parameters=ComprehensiveFCParameters()
)
```

#### 4.2.2 è‡ªå®šä¹‰ç‰¹å¾å‚æ•°

```python
from tsfresh.feature_extraction import EfficientFCParameters

# è‡ªå®šä¹‰ç‰¹å¾æå–å‚æ•°
custom_settings = {
    "length": None,  # åºåˆ—é•¿åº¦
    "mean": None,    # å‡å€¼
    "median": None,  # ä¸­ä½æ•°
    "variance": None, # æ–¹å·®
    "standard_deviation": None,  # æ ‡å‡†å·®
    "maximum": None,  # æœ€å¤§å€¼
    "minimum": None,  # æœ€å°å€¼
    "sum_values": None,  # æ€»å’Œ
    "quantile": [{"q": 0.25}, {"q": 0.75}],  # åˆ†ä½æ•°
    "autocorrelation": [{"lag": 1}, {"lag": 2}],  # è‡ªç›¸å…³
}

features = extract_features(
    df,
    column_id='id',
    column_sort='time',
    default_fc_parameters=custom_settings
)
```

### 4.3 ç‰¹å¾é€‰æ‹©

```python
from tsfresh import select_features
from tsfresh.utilities.dataframe_functions import impute

# å‡è®¾æˆ‘ä»¬æœ‰ç›®æ ‡å˜é‡
y = pd.Series([0, 1], index=[1, 2])

# å¡«å……ç¼ºå¤±å€¼
features_imputed = impute(features)

# åŸºäºå‡è®¾æ£€éªŒé€‰æ‹©ç›¸å…³ç‰¹å¾
features_filtered = select_features(
    features_imputed, 
    y,
    fdr_level=0.05  # å‡å‘ç°ç‡é˜ˆå€¼
)

print(f"åŸå§‹ç‰¹å¾æ•°: {features.shape[1]}")
print(f"ç­›é€‰åç‰¹å¾æ•°: {features_filtered.shape[1]}")
```

---

## 5. é«˜çº§åŠŸèƒ½

### 5.1 å¹¶è¡Œè®¡ç®—

```python
from tsfresh import extract_features
from tsfresh.utilities.distribution import MultiprocessingDistributor

# ä½¿ç”¨å¤šè¿›ç¨‹åŠ é€Ÿ
Distributor = MultiprocessingDistributor(
    n_workers=4,  # ä½¿ç”¨4ä¸ªè¿›ç¨‹
    disable_progressbar=False,
    progressbar_title="Feature Extraction"
)

features = extract_features(
    df,
    column_id='id',
    column_sort='time',
    distributor=Distributor
)
```

### 5.2 Dask åˆ†å¸ƒå¼è®¡ç®—

```python
from tsfresh import extract_features
from tsfresh.utilities.distribution import ClusterDaskDistributor
from dask.distributed import Client

# å¯åŠ¨Daské›†ç¾¤
client = Client()

# ä½¿ç”¨Daskåˆ†å¸ƒå¼è®¡ç®—
Distributor = ClusterDaskDistributor(address=client.scheduler.address)

features = extract_features(
    df,
    column_id='id',
    column_sort='time',
    distributor=Distributor
)
```

### 5.3 æ»šåŠ¨çª—å£ç‰¹å¾æå–

```python
from tsfresh.utilities.dataframe_functions import roll_time_series

# åˆ›å»ºæ»šåŠ¨çª—å£
df_rolled = roll_time_series(
    df,
    column_id='id',
    column_sort='time',
    column_kind=None,
    rolling_direction=1,  # å‘å‰æ»šåŠ¨
    max_timeshift=3       # æœ€å¤§æ—¶é—´çª—å£
)

# æå–æ»šåŠ¨çª—å£ç‰¹å¾
features_rolled = extract_features(
    df_rolled,
    column_id='id',
    column_sort='time'
)
```

### 5.4 ä¸ sklearn é›†æˆ

```python
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from tsfresh.transformers import FeatureSelector, FeatureAugmenter

# åˆ›å»ºæœºå™¨å­¦ä¹ Pipeline
pipeline = Pipeline([
    ('augmenter', FeatureAugmenter(
        default_fc_parameters=MinimalFCParameters()
    )),
    ('selector', FeatureSelector()),
    ('classifier', RandomForestClassifier())
])

# è®­ç»ƒ
pipeline.fit(df, y)

# é¢„æµ‹
predictions = pipeline.predict(df_test)
```

---

## 6. å®é™…åº”ç”¨æ¡ˆä¾‹

### 6.1 é£æ§åœºæ™¯ï¼šç”¨æˆ·è¡Œä¸ºç‰¹å¾æå–

```python
import pandas as pd
from tsfresh import extract_features, select_features
from tsfresh.utilities.dataframe_functions import impute

# ç”¨æˆ·è®¢å•æ—¶é—´åºåˆ—æ•°æ®
orders = pd.DataFrame({
    'user_id': [1, 1, 1, 1, 2, 2, 2],
    'order_time': [0, 1, 3, 7, 0, 2, 5],
    'order_amount': [100, 150, 200, 120, 300, 250, 400],
    'has_overdue': [0, 0, 1, 0, 0, 0, 1]
})

# æå–ç”¨æˆ·è®¢å•é‡‘é¢çš„æ—¶åºç‰¹å¾
amount_features = extract_features(
    orders[['user_id', 'order_time', 'order_amount']],
    column_id='user_id',
    column_sort='order_time'
)

# æå–é€¾æœŸè¡Œä¸ºçš„æ—¶åºç‰¹å¾
overdue_features = extract_features(
    orders[['user_id', 'order_time', 'has_overdue']],
    column_id='user_id',
    column_sort='order_time'
)

# åˆå¹¶ç‰¹å¾
user_features = pd.concat([amount_features, overdue_features], axis=1)

print(f"ç”¨æˆ·ç‰¹å¾ç»´åº¦: {user_features.shape}")
```

### 6.2 é‡‘èåœºæ™¯ï¼šè‚¡ç¥¨ä»·æ ¼ç‰¹å¾

```python
# è‚¡ç¥¨ä»·æ ¼æ—¶é—´åºåˆ—
stock_data = pd.DataFrame({
    'stock_id': ['AAPL'] * 100,
    'date': range(100),
    'close_price': np.random.randn(100).cumsum() + 100,
    'volume': np.random.randint(1000, 10000, 100)
})

# æå–ä»·æ ¼å’Œæˆäº¤é‡ç‰¹å¾
stock_features = extract_features(
    stock_data,
    column_id='stock_id',
    column_sort='date',
    default_fc_parameters=ComprehensiveFCParameters()
)

# æŸ¥çœ‹æå–çš„ç‰¹å¾
print(stock_features.columns[:10])
```

### 6.3 å·¥ä¸šåœºæ™¯ï¼šè®¾å¤‡ä¼ æ„Ÿå™¨æ•°æ®

```python
# ä¼ æ„Ÿå™¨æ—¶é—´åºåˆ—æ•°æ®
sensor_data = pd.DataFrame({
    'device_id': [1] * 1000 + [2] * 1000,
    'timestamp': list(range(1000)) * 2,
    'temperature': np.random.normal(25, 5, 2000),
    'vibration': np.random.normal(0.5, 0.1, 2000),
    'pressure': np.random.normal(100, 10, 2000)
})

# æå–è®¾å¤‡å¥åº·åº¦ç‰¹å¾
device_features = extract_features(
    sensor_data,
    column_id='device_id',
    column_sort='timestamp',
    n_jobs=4  # å¹¶è¡Œå¤„ç†
)

# å¼‚å¸¸æ£€æµ‹
from sklearn.ensemble import IsolationForest

clf = IsolationForest(contamination=0.1)
anomalies = clf.fit_predict(impute(device_features))
```

---

## 7. æœ€ä½³å®è·µ

### 7.1 æ•°æ®é¢„å¤„ç†

```python
# 1. æ£€æŸ¥æ•°æ®è´¨é‡
print(df.isnull().sum())
print(df.dtypes)

# 2. ç¡®ä¿æ—¶é—´åˆ—æœ‰åº
df = df.sort_values(['id', 'time'])

# 3. å¤„ç†å¼‚å¸¸å€¼
df = df[df['value'].between(df['value'].quantile(0.01), 
                             df['value'].quantile(0.99))]

# 4. æ ‡å‡†åŒ–æ—¶é—´é—´éš”ï¼ˆå¦‚æœéœ€è¦ï¼‰
df['time'] = pd.to_datetime(df['time'])
df['time'] = (df['time'] - df.groupby('id')['time'].transform('min')).dt.total_seconds()
```

### 7.2 æ€§èƒ½ä¼˜åŒ–

```python
# 1. ä½¿ç”¨æœ€å°ç‰¹å¾é›†è¿›è¡Œå¿«é€Ÿå®éªŒ
features = extract_features(
    df, 
    column_id='id',
    default_fc_parameters=MinimalFCParameters()
)

# 2. åˆ†æ‰¹å¤„ç†å¤§æ•°æ®
def extract_features_in_batches(df, batch_size=1000):
    ids = df['id'].unique()
    features_list = []
    
    for i in range(0, len(ids), batch_size):
        batch_ids = ids[i:i+batch_size]
        batch_df = df[df['id'].isin(batch_ids)]
        batch_features = extract_features(batch_df, column_id='id')
        features_list.append(batch_features)
    
    return pd.concat(features_list)

# 3. å¯ç”¨å¤šè¿›ç¨‹
features = extract_features(
    df,
    column_id='id',
    n_jobs=8,
    show_warnings=False
)
```

### 7.3 ç‰¹å¾å·¥ç¨‹æŠ€å·§

```python
# 1. ç»„åˆåŸå§‹ç‰¹å¾å’Œtsfreshç‰¹å¾
original_features = df.groupby('id').agg({
    'value': ['count', 'sum']
}).reset_index()

tsfresh_features = extract_features(df, column_id='id')

combined_features = original_features.merge(
    tsfresh_features, 
    left_on='id', 
    right_index=True
)

# 2. æ—¶é—´çª—å£ç‰¹å¾
# æå–æœ€è¿‘7å¤©ã€30å¤©ã€90å¤©çš„ç‰¹å¾
for window in [7, 30, 90]:
    df_window = df[df['time'] >= df['time'].max() - window]
    features_window = extract_features(
        df_window, 
        column_id='id'
    )
    features_window.columns = [f"{col}_last_{window}d" 
                               for col in features_window.columns]
```

---

## 8. å¸¸è§é—®é¢˜

### 8.1 ç‰¹å¾æå–é€Ÿåº¦æ…¢ï¼Ÿ

**è§£å†³æ–¹æ¡ˆï¼š**
- ä½¿ç”¨ `MinimalFCParameters()` å‡å°‘ç‰¹å¾æ•°é‡
- å¯ç”¨å¤šè¿›ç¨‹ `n_jobs=-1`
- ä½¿ç”¨Daskè¿›è¡Œåˆ†å¸ƒå¼è®¡ç®—
- å‡å°‘æ—¶é—´åºåˆ—é•¿åº¦æˆ–é‡‡æ ·

### 8.2 å†…å­˜ä¸è¶³ï¼Ÿ

**è§£å†³æ–¹æ¡ˆï¼š**
```python
# åˆ†æ‰¹å¤„ç†
features = extract_features(
    df, 
    column_id='id',
    chunksize=500  # æ¯æ¬¡å¤„ç†500ä¸ªæ—¶é—´åºåˆ—
)

# æˆ–ä½¿ç”¨Dask
import dask.dataframe as dd
ddf = dd.from_pandas(df, npartitions=10)
```

### 8.3 ç‰¹å¾åŒ…å«å¤§é‡NaNï¼Ÿ

**è§£å†³æ–¹æ¡ˆï¼š**
```python
from tsfresh.utilities.dataframe_functions import impute

# ä½¿ç”¨å†…ç½®çš„å¡«å……æ–¹æ³•
features_imputed = impute(features)

# æˆ–è‡ªå®šä¹‰å¡«å……ç­–ç•¥
features.fillna(0, inplace=True)
features.fillna(features.median(), inplace=True)
```

### 8.4 å¦‚ä½•é€‰æ‹©åˆé€‚çš„ç‰¹å¾å‚æ•°ï¼Ÿ

**å»ºè®®ï¼š**
1. **å¿«é€ŸåŸå‹**ï¼šä½¿ç”¨ `MinimalFCParameters()`
2. **ç²¾ç»†è°ƒä¼˜**ï¼šä½¿ç”¨ `EfficientFCParameters()`
3. **å…¨é¢æ¢ç´¢**ï¼šä½¿ç”¨ `ComprehensiveFCParameters()`
4. **è‡ªå®šä¹‰**ï¼šæ ¹æ®ä¸šåŠ¡éœ€æ±‚å®šä¹‰ç‰¹å®šç‰¹å¾

### 8.5 ä¸å…¶ä»–æ—¶åºåº“çš„å¯¹æ¯”

| åº“ | ä¼˜åŠ¿ | åŠ£åŠ¿ | é€‚ç”¨åœºæ™¯ |
|----|------|------|----------|
| **tsfresh** | å…¨è‡ªåŠ¨ã€ç‰¹å¾ä¸°å¯Œ | è®¡ç®—å¼€é”€å¤§ | è¡¨æ ¼æ•°æ®+æ—¶åºç‰¹å¾ |
| **tslearn** | æ—¶åºåˆ†ç±»/èšç±» | ç‰¹å¾æå–æœ‰é™ | æ—¶åºæ¨¡å¼è¯†åˆ« |
| **statsmodels** | ç»Ÿè®¡å»ºæ¨¡ä¸“ä¸š | æ‰‹åŠ¨ç‰¹å¾å·¥ç¨‹ | æ—¶åºé¢„æµ‹ |
| **prophet** | é¢„æµ‹å‡†ç¡® | ä¸é€‚åˆç‰¹å¾æå– | æ—¶åºé¢„æµ‹ |

---

## 9. å‚è€ƒèµ„æº

### 9.1 å®˜æ–¹æ–‡æ¡£
- å®˜ç½‘ï¼šhttps://tsfresh.readthedocs.io/
- GitHubï¼šhttps://github.com/blue-yonder/tsfresh
- è®ºæ–‡ï¼š*tsfresh: A Python package for automatic extraction of relevant features from time series*

### 9.2 ç›¸å…³æ•™ç¨‹
- [å®˜æ–¹ç¤ºä¾‹é›†](https://tsfresh.readthedocs.io/en/latest/text/quick_start.html)
- [APIæ–‡æ¡£](https://tsfresh.readthedocs.io/en/latest/api/tsfresh.html)
- [ç‰¹å¾è®¡ç®—å™¨åˆ—è¡¨](https://tsfresh.readthedocs.io/en/latest/text/list_of_features.html)

### 9.3 å®æˆ˜æ¡ˆä¾‹
- é‡‘èé£æ§ï¼šå®¢æˆ·è¡Œä¸ºåºåˆ—åˆ†æ
- å·¥ä¸šåˆ¶é€ ï¼šè®¾å¤‡æ•…éšœé¢„æµ‹
- åŒ»ç–—å¥åº·ï¼šç”Ÿç†ä¿¡å·åˆ†æ
- é›¶å”®ç”µå•†ï¼šç”¨æˆ·è´­ä¹°æ¨¡å¼æŒ–æ˜

---

## 10. æ€»ç»“

### 10.1 æ ¸å¿ƒä»·å€¼

tsfresh çš„æ ¸å¿ƒä»·å€¼åœ¨äºï¼š
1. **è‡ªåŠ¨åŒ–**ï¼šæ— éœ€äººå·¥è®¾è®¡ç‰¹å¾
2. **å…¨é¢æ€§**ï¼š800+ ç§ç‰¹å¾è¦†ç›–å„ä¸ªç»´åº¦
3. **ç§‘å­¦æ€§**ï¼šåŸºäºç»Ÿè®¡å­¦çš„ç‰¹å¾é€‰æ‹©
4. **å®ç”¨æ€§**ï¼šä¸ä¸»æµMLåº“æ— ç¼é›†æˆ

### 10.2 ä½¿ç”¨å»ºè®®

- âœ… **é€‚åˆä½¿ç”¨**ï¼šæœ‰å¤§é‡æ—¶é—´åºåˆ—æ•°æ®ï¼Œéœ€è¦å¿«é€Ÿæ¢ç´¢ç‰¹å¾
- âœ… **é€‚åˆä½¿ç”¨**ï¼šæ—¶åºæ•°æ®ç»´åº¦é«˜ï¼Œäººå·¥ç‰¹å¾å·¥ç¨‹å›°éš¾
- âŒ **ä¸é€‚åˆ**ï¼šæ•°æ®é‡å°ï¼Œç®€å•ç»Ÿè®¡ç‰¹å¾å³å¯æ»¡è¶³
- âŒ **ä¸é€‚åˆ**ï¼šå¯¹è®¡ç®—èµ„æºå’Œæ—¶é—´è¦æ±‚ä¸¥æ ¼

### 10.3 ä¸‹ä¸€æ­¥å­¦ä¹ 

1. å®è·µå®˜æ–¹æ•™ç¨‹æ¡ˆä¾‹
2. åœ¨å®é™…é¡¹ç›®ä¸­åº”ç”¨ tsfresh
3. å­¦ä¹ å¦‚ä½•è°ƒä¼˜ç‰¹å¾æå–å‚æ•°
4. æ¢ç´¢ä¸æ·±åº¦å­¦ä¹ çš„ç»“åˆ

---

**æ–‡æ¡£ç‰ˆæœ¬ï¼š** v1.0  
**æ›´æ–°æ—¥æœŸï¼š** 2025-01-01  
**ç»´æŠ¤è€…ï¼š** AI Assistant
